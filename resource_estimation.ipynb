{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703f1c93-cfb4-4eff-9f10-ad59b6698fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da67b7b1-7cb5-4c3f-8506-9f382e6a0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_flops_per_token(n_layers, n_heads, d_model, n_ctx, n_vocab, ff_ratio=4):\n",
    "    \"\"\"Open AI method for forward pass FLOPs counting of decoder-only Transformer\n",
    "    \"\"\"\n",
    "    d_attn = d_model // n_heads\n",
    "    d_ff = d_model * ff_ratio\n",
    " \n",
    "    embeddings = 4 * d_model\n",
    "    attn_qkv = 2 * n_layers * d_model * 3 * (d_attn * n_heads)\n",
    "    attn_mask = 2 * n_layers * n_ctx * (d_attn * n_heads)\n",
    "    attn_project = 2 * n_layers * (d_attn * n_heads) * d_model\n",
    "    ff = 2 * n_layers * 2 * d_model * d_ff\n",
    "    logits = 2 * d_model * n_vocab\n",
    " \n",
    "    return embeddings + attn_qkv + attn_mask + attn_project + ff + logits\n",
    "\n",
    "def deepmind_flops_per_sequence(n_layers, n_heads, d_model, n_ctx, n_vocab, ff_ratio=4):\n",
    "    \"\"\"DeepMind method for forwad pass FLOPs counting of decoder-only Transformer\n",
    "    \"\"\"\n",
    "    d_attn = d_model // n_heads\n",
    "    d_ff = d_model * ff_ratio\n",
    " \n",
    "    embeddings = 2 * n_ctx * n_vocab * d_model\n",
    " \n",
    "    attn_qkv = 2 * n_ctx * 3 * d_model * (d_attn * n_heads)\n",
    "    attn_logits = 2 * n_ctx * n_ctx * (d_attn * n_heads)\n",
    "    attn_softmax = 3 * n_heads * n_ctx * n_ctx\n",
    "    attn_reduce = 2 * n_ctx * n_ctx * (d_attn * n_heads)\n",
    "    attn_project = 2 * n_ctx * (d_attn * n_heads) * d_model\n",
    "    total_attn = attn_qkv + attn_logits + attn_softmax + attn_reduce + attn_project\n",
    " \n",
    "    ff = 2 * n_ctx * (d_model * d_ff + d_model * d_ff)\n",
    " \n",
    "    logits = 2 * n_ctx * d_model * n_vocab\n",
    " \n",
    "    return embeddings + n_layers * (total_attn + ff) + logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf02eadc-9ac5-4f47-b59a-836292c7cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_layers = 12; d_model = 768; n_heads = 12; n_vocab = 50257; n_ctx = 4096\n",
    "n_layers = 24; d_model = 1024; n_heads = 16; n_vocab = 50257; n_ctx = 4096\n",
    "\n",
    "openai_fpt = openai_flops_per_token(n_layers, n_heads, d_model, n_ctx, n_vocab, ff_ratio=4)\n",
    "deepmind_fpt = openai_flops_per_token(n_layers, n_heads, d_model, n_ctx, n_vocab, ff_ratio=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700d1aec-96fd-4c3d-a614-2b9f24607468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908236800\n",
      "908236800\n"
     ]
    }
   ],
   "source": [
    "print(openai_fpt)\n",
    "print(deepmind_fpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4816b6-f7a2-4a0b-8dad-26c1e01b7d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
